- # 쿠버네티스(Kubernetes)
	- 쿠버네티스(Kubernetes, K8s)는 컨테이너화된 애플리케이션의 자동 디플로이, 스케일링 등을 제공하는 관리 시스템으로 오픈 소스 기반이다.
	- 원래 구글에 의해 설계되었고 현재 리눅스 재단에 의해 관리되고 있다.
	- ## 쿠버네티스의 장단점
		- ### 장점
			- 자동 배포
			- 모니터링
			- 자동복구
		- ### 단점
			- 시스템 자원 소모
			- 높은 학습 난이도
			- 높은 진입 장벽
	- ## 쿠버네티스 구조
		![](https://i.imgur.com/ZWdlxm3.png)
- # 쿠버네티스 설치
	- ## 쿠버네티스 마스터 노드 설정
		```
		sudo -i
		modprobe br_netfilter
		```
		- **modprode**: 리눅스 커널 모듈 관리 도구, 특정 모듈을 로드하거나 제거 가능
		- 브릿지 네트워크 인터페이스에 대한 트래픽이 iptables 규칙에 의해 처리되도록 함
		```
		sysctl net.bridge.bridge-nf-call-iptables=1
		```
		- **br_netfilter**: 네트워크 패킷 처리 관련 커널 모듈, iptables/netfilter 규칙 적용되게함.
			즉, 컨테이너와 호스트 간의 인터페이스 등에서 발생하는 트래픽에 대해 규칙을 적용해 트래픽을 관리한다는 뜻
		- 커널이 처리하는 패킷을 외부로 포워딩(IP forwarding)기능
		```
		vim /etc/sysctl.conf
		# 마지막에 두줄 추가
		net.bridge.bridge-nf-call-iptables=1
		net.ipv4.ip_forward=1
		```
		
		![](https://i.imgur.com/9JPEWNy.png)
		- Swap 에 0으로 나와야함!!
		- **swap이 활성화 되어있는 경우**
			![](https://i.imgur.com/sMuPrxx.png)
			```
			sudo -i
			swapoff --all
			free -h
			cat /proc/swaps
			vim /etc/fstab
			shutdown -r now
			```
	- ## container 적용
		```
		sudo mkdir -p /etc/containerd
		containerd config default | sudo tee /etc/containerd/config.toml > /dev/null
		```
		- containerd config default : containerd의 기본 설정 출력
		- tee : 입력 받은 데이터를 파일에 쓰면서 동시에 표준 출력으로 내보냄
		- > /dev/null : 화면에 출력하는 내용을 버리기 위해 사용
		```
		sudo vim /etc/containerd/config.toml
		/SystemdCgroup    # 검색
		SystemdCgroup = false -> true 로 변경
		
		sudo systemctl restart containerd
		sudo systemctl enable containerd
		sudo systemctl status containerd
		```
	- ## 쿠버네티스 설치(모든 노드에 설치)
		```
		sudo apt-get update
		
		sudo apt-get install -y apt-transport-https ca-certificates curl
		
		# 아래는 공식 홈페이지와 다름 !!주의!!
		sudo mkdir -p /etc/apt/keyrings
		
		sudo curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
		
		echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
		
		sudo apt-get update
		
		sudo apt-get install -y kubelet kubeadm kubectl
		
		sudo apt-mark hold kubelet kubeadm kubectl
		```
	- ## 쿠버네티스 설치 확인
		```
		sudo -i
		kubelet --version
		kubeadm version
		kubectl version --output=yaml
		```
		- ### 인증서 상태 확인
		```
		kubeadm certs check-expiration
		```
		- ### kubeadm이 사용할 수 있는 이미지 출력
		```
		kubeadm config images list
		```
	- ## 마스터 노드 설정
		```
		kubeadm config images pull --cri-socket /run/containerd/containerd.sock
		
		kubeadm init --apiserver-advertise-address=인스턴스 프라이빗IP --pod-network-cidr=192.168.0.0/16 --cri-socket /run/containerd/containerd.sock
		```
		- calico: 192.168.0.0/16 <-현업에서 주로 사용
		- flannel: 10.244.0.0/16 <- 간단할때 사용함
		```
		kubeadm certs check-expiration
		exit
		```
	- ## 쿠버네티스 설치
		```
		# root계정 말고 user계정으로도 사용 가능 하도록 설정
		mkdir -p $HOME/.kube
		sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
		sudo chown $(id -u):$(id -g) $HOME/.kube/config
		```
	- ### calico 설치
		- https://docs.tigera.io/calico/latest/getting-started/kubernetes/self-managed-onprem/onpremises
		```
		mkdir app
		cd app
		
		kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/tigera-operator.yaml
		
		curl https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/custom-resources.yaml -O
		```
		![](https://i.imgur.com/CEVrCRi.png)
		```
		kubectl create -f custom-resources.yaml
		
		watch kubectl get pods -n calico-system
		# STATUS Running 확인 (약 1분정도 기다려야 Running 상태가 된다.)
		```
		- #### 참고) 쿠버네티스 cni설치(2) - flannel
			```
			kuberctl apply -f https://github.com/flannel/releases/latest/download/kube-flannel.yml
			```
			- ##### (2)이 안된다면
				```
				wget https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
				kubectl apply -f kube-flannel.yml
				```
		- ### 마스터노드에도 파드 생성하도록 설정
			```
			kubectl get node
			kubectl describe node 노드이름 | grep Taints
			
			# Taints 안만든다 -> untainted로 변경
			kubectl taint nodes --all node-role.kubernetes.io/control-plane-
			```
	- ## 마스터 노드의 설정 가지고 오기
		```
		mkdir -p $HOME/.kube
		scp -p 마스터노드유저@마스터노드IP:~/.kube/config ~/.kube/config
		
		sudo -i
		```
	- ## hello world!
		```
		kubectl run hello-world --image=hello-world --restart=Never
		kubectl get pod
		ubectl get pod -o wide
		```
		- IP는 pod의 IP
	- ## 로그 확인하기
		```
		kubectl get pod
		kubectl logs {pod NAME}
		```
	- 쿠버네티스 기초
	- 디플로이먼트 : 파드 안에 컨테이너 파드가 여러개 일수 있음 파드 여러개를 묶는것을 말한다.
		- 레플리카셋 : 디플로이먼트 안의 파드를 관리하는것
	- 서비스 : 디플로이먼트가 EC2에서 유저에게 보내는것
	- 스토리지볼륨 : 도커볼륨 과 같은 역할
	- 스테이트풀셋 : 순서가 있는 컨테이너
	- 인그레스 : 서비스가 여러개 일때 인그레스를 통해서 나간다
	- 잡, 크론잡 : 배치작업 할때, 크론탭과 같은 역할
		```
		# 클러스터 정보
		kubectl cluster-info
		
		# 노드 정보
		kubectl get node
		
		# 파드 정보
		kubectl get pod
		```
	- ## pod 삭제
		```
		kubectl delete pod {pod NAME}
		```
	- ## 매니페스트(Manifest)의 개념
		- 매니페스트란 쿠버네티스 오브젝트를 생성하기 위한 메타정보를 YAML로 기술한 파일
	- ## 매니패스트 작성
		```
		~/work/k8s/basic$ vim nginx-test01.yml
		```
		![400](https://i.imgur.com/VX3HP7f.png) _들여쓰기, 대소문자 주의!!_
	- ## $ kubectl apply -f {파일 이름}
		- apply 명령어는 쿠버네티스 리소스를 정의하는 파일을 통해 애플리케이션을 관리
		- kubectl apply 명령어를 통해 쿠버네티스 리소스를 생성하거나 업데이트 할 수 있다
		```
		kubectl apply -f nginx-test01.yml
		kubectl get pod
		# STATUS Running 확인
		```
		- 삭제
			```
			kubectl delete -f {파일 이름}
			```
	
	- 용어
		- 서버
			- 클라이언트 : 요청을 하는쪽
			- 서버 : 요청을 받는쪽
		- 노드
			- 클러스터 : 덩어리, 어떤 역할을 하는 서버 모임, 마스터
			- 노드 : 팀원
				- 서버와 노드는 비슷하지만 다름
		- API
			- API서비스 : 음식점 -> 밥을 볶아 -> 양파 잘게 -> 당근 -> 파 -> 볶아 -> 자장소스 -> ...
				- -> 이걸 모아서 볶음밥
				- 서비스 에서 제공하는 것만 제공함
			- API서버 : 볶음밥 만드는 주방장(요청을 받는쪽)
				- ~/work/docker/flaskapp <- flaskapp이 API 서버
				-  ~/flaskapp/myapp/main.py <- 이게 주방장? API 서버
		- flask
	
	![](https://i.imgur.com/QAfETUZ.png)
- # 디플로이먼트
	- ## 디플로이먼트(deployment)의 개념
		- 디플로이먼트는 파드와 레플리카셋에 대한 선언적 업데이트를 제공
			- ex) 파드 상태 업데이트, 스케일업
		- 디플로이먼트를 활용해 새로운 레플리카셋을 생성하거나 기존에 존재하는 디플로이먼트를 제거하고 새로운 디플로이먼트를 선언할 수도 있다.
		- 주의사항 : 레플리카셋을 직접적으로 관리하는 것은 안됨.
	- ## 레플리카셋(replicaset)의 개념
		- 레플리카셋은 여러 개의 파드를 항상 안정적으로 유지하는 것이 목적
		- 레플리카셋은 주로 특정 개수의 파드 실행을 보장하는데 사용
		- 예를 들어, 3개의 파드가 실행되어야 한다면, 3개중 1개가 정지되면 새로운 파드를 생성해서 3개 파드의 개수를 맞춤
	- ## 디플로이먼트 vs 레플리카셋
		- 디플로이먼트는 레플리카셋 보다 상위 개념이다.
		- 디플로이먼트가 생성되면 해당 디플로이먼트에 대한 레플리카셋이 자동으로 생성됨.
		- 따라서 사용자는 레플리카셋을 직접적으로 관리할 필요없음.
	- ## 디플로이먼트 실행
		```
		kubectl create deployment deploy-hello --image=hello-world
		kubectl get all
		```
		- ### 디플로이먼트, 레플리카셋, 파드 확인
			```
			# ,뒤에 띄워쓰기 금지
			kubectl get deployment,replicaset,pod
			
			# 줄여서 작성 가능
			kubectl get deploy,rs,po
			```
		- ### 디플로이먼트 삭제
			```
			kubectl delete deployment deploy-hello
			kubectl get deploy,rs,po
			```
	- ## 레플리카셋 조정
		```
		kubectl create deployment deploy-nginx --image=nginx --replicas=3
		kubectl get deploy,rs,po
		kubectl get deploy,rs,po -o wide
		```
		![400](https://i.imgur.com/R9QvfLG.png)  **pod가 3개가 됨**
		![](https://i.imgur.com/tLePWP7.png)
	- ## 파드 삭제 후 재생성
		```
		kubectl delete pod {NAME에 pod/ 뒤 deploy- 부터 끝까지}
		kubectl delete pod deploy-nginx-7f979874cf-xg2nn
		kubectl get deploy,rs,po -o wide
		```
		![](https://i.imgur.com/QFMmc5r.png)
		- 새로 생긴것 확인(AGE 보면 생성 시간이 다름!)
	- deployment 삭제
		```
		kubectl delete deployment deploy-nginx
		kubectl get deploy,rs,po
		```
- # 매니페스트를 통한 디플로이먼트 실행
	- ## 매니페스트 파일 작성
	```
	~/work/k8s/basic$ vim deploy-test01.yml
	
	apiVersion: apps/v1
	kind: Deployment
	metadata:
	  name: deploy-test01
	spec:
	  replicas: 3
	  selector:
	    matchLabels:
	      app: web-deploy
	  template:
	    metadata:
	      labels:
	        app: web-deploy
	    spec:
	      containers:
	      - name: nginx
	        image: nginx:latest
	```
	![400](https://i.imgur.com/IDILmnD.png)
	- ## 실행
		```
		kubectl apply -f deploy-test01.yml
		kubectl get deploy,rs,po
		```
	- ## 스케일 조정
		```
		cp deploy-test01.yml deploy-test02.yml
		vim deploy-test02.yml
		
		# 수정
		replicas: 5
		
		kubectl get pod
		```
		![400](https://i.imgur.com/zb1jcZx.png)
		```
		kubectl apply -f deploy-test02.yml
		kubectl get pod
		```
		![400](https://i.imgur.com/AdSO4ws.png)
		- ### 삭제
			```
			kubectl delete -f deploy-test02.yml
			kubectl get pod
			```
			![400](https://i.imgur.com/Ztdk5yn.png)
			- deoploy-test01이 지워졌다고 출력됨
				![150](https://i.imgur.com/qdVtgju.png)
- # 롤아웃
	- ## 매니페스트 파일 작성
		```
		cp deploy-test01.yml deploy-test03.yml
		vim deploy-test03.yml
		
		# 수정
		image: nginx:1.24
		```
	- ## 실행
		```
		kubectl apply -f deploy-test03.yml
		kubectl get deploy,po
		
		kubectl describe deployment deploy-test01
		```
		![200](https://i.imgur.com/qlH6Zd0.png)
		- describe = log 같은 느낌 
	- ## 버전 UP 매니페스트 파일 작성
		```
		cp deploy-test03.yml deploy-test04.yml
		vim deploy-test04.yml
		image: nginx:1.25
		diff deploy-test03.yml deploy-test04.yml
		```
		- 리눅스명령어 diff {파일명} {파일명} : 두개의 파일의 달라진점
			![400](https://i.imgur.com/yKxPs0J.png)
	- ## 실행
		```
		kubectl apply -f deploy-test04.yml
		kubectl get deploy,rs,pod
		kubectl describe deployment deploy-test01
		```
		![150](https://i.imgur.com/XisFFt4.png)
		- ### 실행 전
			![400](https://i.imgur.com/rwMNEjm.png)
		- ### 실행 후
			![400](https://i.imgur.com/Wf3pxYC.png)
		- pod 들이 내려갔다가 새로 생성됨
		- NAME이 바뀌고 AGE도 확인
- # 롤백
	```
	kubectl rollout undo deployment deploy-test01
	kubectl get pod
	kubectl describe deployment deploy-test01
	```
	![400](https://i.imgur.com/6jNaSYQ.png)
	![150](https://i.imgur.com/u0TcAWD.png)
	- ## 삭제
		```
		kubectl delete -f deploy-test04.yml
		kubectl get deploy,rs,po
		```
- # 서비스
	- ## 서비스의 개념
		- 디플로이먼트는 레플리카셋보다 상위 개념이다.
		- 디플로이먼트가 생성되면 해당 디플로이먼트에 대한 레플리카셋이 자동으로 생성됨.
		- 따라서 사용자는 레플리카셋을 직접적으로 관리할 필요없음.
		clusterIP: 모든 통신은 쿠버네티스에서만 통신함 (내부 통신)
		NodePort : 뒤에 개구멍을 만들어서 접속
		LoadBalancer: 정문으로 들어옴
	- ## ClisterIP
		```
		vim service-test01.yml
		
		apiVersion: v1
		kind: Service
		metadata:
		  name: web-service
		spec:
		  selector:
		    app: web-deploy
		  type: ClusterIP
		  ports:
		  - protocol: TCP
		    port: 80
		```
		![400](https://i.imgur.com/mWLohkm.png)
		- ### 디플로이먼트 실행
			```
			kubectl apply -f deploy-test01.yml
			kubectl apply -f service-test01.yml
			```
		- ### 서비스, 디플로이먼트 확인
			![400](https://i.imgur.com/TvJ21DR.png)
			- service/web-service 추가된것 확인
		- ### 접속 확인을 위한 nginx 파드 실행
			```
			kubectl apply -f nginx-test01.yml
			kubectl get all
			```
			- pod/nginx01
		- ### 접속 확인
			```
			kubectl exec -it nginx01 -- /bin/bash
			/# curl "service/web-service의 CLUSTER IP:80"
			10.100.131.213
			/# exit
			```
		- ### 실습 종료
			```
			kubectl delete -f service-test01.yml
			kubectl delete -f nginx-test01.yml
			kubectl delete -f deploy-test01.yml
			kubectl get all
			```
	- ## NodePort
		- ### NodePort의 파일 생성
			```
			vim service-test02.yml
			
			apiVersion: v1
			kind: Service
			metadata:
			  name: web-service-nodeport
			spec:
			  selector:
			    app: web-deploy
			  type: NodePort
			  ports:
			  - protocol: TCP
			    nodePort: 31001
			    port: 80
			    targetPort: 80
			```
			![400](https://i.imgur.com/hpVTDz1.png)
		- ### NodePort실행
			```
			kubectl apply -f deploy-test01.yml
			kubectl apply -f service-test02.yml
			
			kubectl get all
			```
			![](https://i.imgur.com/ROCtB2d.png)
			- service/web-service-nodeport 확인
			- 인스턴스 퍼블릭 IP 주소:31001 접속
			![400](https://i.imgur.com/LuOv7XA.png)
		- ### 실습 종료
			```
			kubectl delete -f deploy-test01.yml
			kubectl delete -f service-test02.yml
			
			kubectl get all
			```
	- ## LoadBalancer
		![400](https://i.imgur.com/HoUcUJE.png)
		![400](https://i.imgur.com/06PDlPu.png)
- # 스토리지 볼륨의 개념
	![400](https://i.imgur.com/ktIbZ7j.png)
	- emptyDir : pod가 고장 나면 못씀 1회용
	- hostPath: Node가 고장나면 못쓴다
	- PersistentVolume(PV) : 다른 서버에 둬서 고장나도 사용 가능
	- ## emptyDir
		- ### 파일 생성
			```
			vim volume-test01.yml
			
			apiVersion: v1
			kind: Pod
			metadata:
			  name: nginx-volume-01
			spec:
			  containers:
			  - name: nginx-test01
			    image: nginx:latest
			    volumeMounts:
			    - name: empty-test01
			      mountPath: /mount01
			  volumes:
			  - name: empty-test01
			    emptyDir: {}
			```
		- ### 볼륨 실행
			```
			kubectl apply -f volume-test01.yml
			kubectl get pod
			
			kubectl exec -it nginx-volume-01 -- /bin/bash
			
			/# ls
			/# cd mount01/
			
			/mount01# echo "volume test" > ./test.txt
			
			/mount01# ls
			test.txt
			
			/mount01# cat test.txt
			volume test
			
			/mount01# exit
			```
		- ### 볼륨 삭제 후 다시 실행
			```
			kubectl delete -f volume-test01.yml
			kubectl apply -f volume-test01.yml
			kubectl get pod
			
			kubectl exec -it nginx-volume-01 -- /bin/bash
			
			/# cd mount01
			/mount01# ls 
				# 파드 삭제 후 재생성 하면 이전 파일이 존재하지 않는것을 볼 수 있다.
			/mount01# exit
			```
		- 실습 중료
			```
			kubectl delete -f volume-test01.yml
			kubectl get pod
			```
	- ## hostPath
		- 경로를 pod와 연결을 시켜서
		```
		kubectl get node --show-labels
		
		kubernetes.io/hostname=ip-172-31-5-139
		```
		![](https://i.imgur.com/OJb2pSe.png)
		```
		~/work/k8s/basic$ mkdir volhost01
		~/work/k8s/basic$ cd volhost01
		~/work/k8s/basic/volhost01$ pwd
		
		/home/ubuntu/work/k8s/basic/volhost01
		
		cd ..
		```
		- ### 파일 생성
		```
		vim volume-test02.yml
		
		apiVersion: v1
		kind: Pod
		metadata:
		  name: nginx-volume-02
		spec:
		  nodeSelector:
		    kubernetes.io/hostname: ip-172-31-5-139
		  containers:
		  - name: nginx-test01
		    image: nginx:latest
		    volumeMounts:
		    - name: hostpath-test01
		      mountPath: /mount01
		  volumes:
		  - name: hostpath-test01
		    hostPath:
		      path: /home/ubuntu/work/k8s/basic/volhost01
		      type: DirectoryOrCreate
		```
		- ### 실행
			```
			kubectl apply -f volume-test02.yml
			kubectl exec -it nginx-volume-02 -- /bin/bash
			/# ls
			/# cd mount01/
			/mount01# ls
			/mount01# echo "hello world 01" > ./test01.txt
			/mount01# ls
			test01.txt
			
			~/work/k8s/basic$ cd volhost01
			~/work/k8s/basic/volhost01$ ls
			test01.txt
			~/work/k8s/basic/volhost01$ cat test01.txt
			hello world 01
			~/work/k8s/basic/volhost01$ cd ..
			```
		- ### 파드 삭제 후 다시 생성 후 파일 확인
			```
			kubectl delete -f volume-test02.yml
			kubectl get pod
			kubectl apply -f volume-test02.yml
			kubectl get pod
			
			kubectl exec -it nginx-volume-02 -- /bin/bash
			/# ls
			/# cd mount01/
			/mount01# ls
			test01.txt
			/mount01# cat test01.txt
			hello world 01
			```
		- 실습 종료
			```
			kubectl delete -f volume-test02.yml
			kubectl get all
			```
	- ## PersistentVolume(PV)
		- ### 실습
			```
			sudo -i
			
			~# cd /tmp/
			/tmp# ls
			
			/tmp# mkdir k8spv
			/tmp# ls
			
			/tmp# exit
			
			
			```
			
			```
			sudo apt install nfs-common
			```
			**NFS(Network File System)**: 네트워크로 연결된 다른 컴퓨터의 파일 시스템을 내 컴퓨터로 마운트 해서 상대방의 파일 시스템 일부를 자기 자신의 디렉토리 처럼 사용하는 프로토콜. 쉽게 말해 저장공간을 공유할 수 있도록 해주는 서비스
			```
			sudo apt install nfs-kernel-server -y
			```
			```
			systemctl status nfs-server.service
			sudo vim /etc/exports
			...(가장 하단에 추가)
			/tmp/k8spv {인스턴스 프라이빗IP}(rw,no_root_squash)
				# 클라이언트가 루트 권한 획득 가능하게 함
			
			sudo systemctl restart nfs-server
			systemctl status nfs-server.service
			```
			- PV를 만든것
			```
			(ip-172-31-5-139)
			vim volume-test04-1-pv.yml
			
			apiVersion: v1
			kind: PersistentVolume
			metadata:
			  name: pv-01
			spec:
			  accessModes:
			  - ReadWriteOnce
			  capacity:
			    storage: 100Mi
			  persistentVolumeReclaimPolicy: Retain
			  storageClassName: pv-test-01
			  nfs:
			    server: 172.31.5.139
			    path: /tmp/k8spv
			```
			- 요청서를 만든것(PVC)
			```
			vim volume-test04-2-pv.yml
			
			apiVersion: v1
			kind: PersistentVolumeClaim
			metadata:
			  name: pvc-01
			spec:
			  accessModes:
			  - ReadWriteOnce
			  resources:
			    requests:
			      storage: 30Mi
			  storageClassName: pv-test-01
			```
			
			```
			vim volume-test04-3-pod.yml
			
			apiVersion: v1
			kind: Pod
			metadata:
			  name: nginx-volume-04
			spec:
			  containers:
			  - name: nginx-test01
			    image: nginx:latest
			    volumeMounts:
			    - name: nfs-pv-01
			      mountPath: /mount01
			  volumes:
			  - name: nfs-pv-01
			    persistentVolumeClaim:
			      claimName: pvc-01
			```
		- 실행
			```
			kubectl apply -f volume-test04-1-pv.yml
			kubectl get pv
			kubectl apply -f volume-test04-2-pvc.yml
			kubectl get pvc
			```
			
			```
			kubectl exec -it nginx-volume-04 -- /bin/bash
			/# cd mount01
			/mount01# echo "hello nfs pv" > ./nfs_pvtest.txt
			
			/mount01# ls
			nfs_pvtest.txt
			
			/mount01# cat nfs_pvtest.txt
			hello nfs pv
			
			exit
			```
			```
			cd /tmp/k8spv/
			
			/tmp/k8spv$ ls
			nfs_pvtest.txt
			
			/tmp/k8spv$ cat nfs_pvtest.txt
			hello nfs pv
			```
		- 실습 종료
			```
			kubectl delete -f volume-test04-3-pod.yml
			kubectl delete -f volume-test04-2-pvc.yml
			kubectl delete -f volume-test04-1-pv.yml
			kubectl get all
			```
- # 스테이트풀셋 (개념만)
	- statefulset은 순서가 있는 파드 배포에 사용함
- # 인그레스의 개념
	- 쿠버네티스 외부에서의 요청을 쿠버네티스 내부로 이어줌
	- ## 헬름(helm)
		- 쿠버네티스 애플리케이션을 운영을 위해서는 yaml파일 관리 필요
		- 헬름은 헬름 차트라고 불리우는 쿠버네티스 패키지를 관리하는 도구
			- 헬름은 쿠버네티스 애플리케이션 관리를 도와주는 소프트웨어
			- 새로운 차트 생성
			- 쿠버네티스 클러스터 내부에 존재하는 차트 설치 및 삭제
		- 헬름 차트(helm chart)는 쿠버네티스 리소스를 생성하기 위해 필요한 파일을 모아놓은 것
			- 헬름 차트를 활용하면 쿠버네티스 애플리케이션을 설치하거나 업데이트를 쉽게 할 수 있음
		- ### 헬름 설치
			```
			cd
			cd app
			
			curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
			
			ls
			get_helm.sh
			
			chmod 700 get_helm.sh
			
			# 설치
			./get_helm.sh 
			
			# 설치 확인
			helm version
			```
		- 레포지토리 추가
			```
			helm repo add bitnami https://charts.bitnami.com/bitnami
			
			helm repo update
			```
		- nginx-ingress-controller 설치
			```
			helm search repo nginx
			
			# 파일 다운로드
			helm pull bitnami/nginx-ingress-controller
			ls
			
			# 압축 풀기
			tar xvfz nginx-ingress-controller-11.3.2.tgz
			ls
			
			# 파일 이름 변경
			mv nginx-ingress-controller nginx-ingress-controller-11.3.2
			ls
			```
		- my-valuses.yaml 파일 생성
			```
			cd nginx-ingress-controller-11.3.2/
			# 파일 복사
			cp values.yaml my-values.yaml
			```
		- 네임스페이스 생성
			- 파드를 분리해서 관리할수 있음
			```
			kubectl get namespace
			# 우리가 사용하는 네임스페이스는 default
			
			kubectl create namespace mynginx
			kubectl get namespace
			
			helm install --namespace mynginx --generate-name bitnami/nginx-ingress-controller -f my-values.yaml
			
			# 설치 확인
			helm ls --namespace mynginx
			```