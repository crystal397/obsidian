### 8.5 외부 데이터 수집과 크롤링

- **외부 데이터 수집의 필요성**
	- 다양한 데이터를 체계적으로 수집하는 경우가 드물어 외부 데이터 수집, 활용 필요
	- 분석 목적을 명확히 정의하고 이에 맞는 외부  데이터를 찾아 수집해야 함
	- 일반적으로 다수의 경로에서 다양한 데이터를 한번에 수집한 뒤, 모델이나 분석 목적에 맞게 통합, 가공 후 비즈니스에 활용함![[스크린샷 2024-06-09 오후 7.55.22.png]]

- **외부데이터 수집 방법**
	- 데이터 판매 전문 기업으로부터 필요 데이터를 구매하거나 MOU 등을 통해 공유 받음
		- 장점: 정제된 고품질 데이터 확보 가능
		- 단점: 비용
	- 공공 오픈 데이터 제공 사이트에서 엑셀이나 csv형태로 데이터를 받음
		- 장점: 특별한 비용이나 노력없이 쉽게 확보 가능
		- 단점: 원하는 형태로 가공하기 위한 리소스 필요하며, 활용성이 낮고 큰 가치를 가진 데이터가 적음
	- 웹 데이터 크롤링
		- 장점: 원하는 데이터를 실시간으로 자유롭게 수집 가능
		- 단점: 프로그래밍 필요, 웹페이지가 리뉴얼되면 이에 맞춰 코드 수정, 법리적 이슈

- **크롤링(Crawling)이란?**
	- Web상을 돌아다니면서 정보를 수집하는 것을 의미
	- 크롤링과 스크래핑(Scraping)의 차이
		- 크롤링: 웹 페이지가 주어지면 해당 페이지 내 링크들을 따라가면서 모든 내용을 가져옴
		- 스크래핑: 웹 페이지 내에서 자신이 원하는 부분의 정보만 가져옴
			- 예) 가격 비교 사이트의 제품과 가격데이터 수집, 날씨 정보 사이트의 날씨 데이터 수집 등
	-  편의상 스크래핑도 크롤링으로 통칭
	-  API를 통해 정리된 데이터를 제공받거나, 코딩해서 원하는 데이터 수집
		- 파이썬에서 BeautifulSoup이나 Selenium 활용

- **크롤링 방법**
	- 웹사이트 내 robots.txt 파일을 통해 크롤링 허용 범위 확인
		- User-agent : 대상 크롤러(모든 검색봇 , 구글봇 등) 
		- Allow: 허용하는 경로
		- Disallow: 허용하지 않는 경로
	- 웹사이트의 HTML 구조 활용
		- 데이터가 있는 위치를 사전에 설정하여 자동 반복적으로 특정 위치의 텍스트 수집
			- 크롬 브라우저 'F12'키를 눌러 개발자 도구 확인
			- 원하는 위치에 마우스 커서를 대 해당 영역의 소스 코드 확인
			- 수집하고자 하는 데이터의 구조적 위치 확인 후 파이썬 코드에 삽입![[스크린샷 2024-06-09 오후 8.31.42.png]]


