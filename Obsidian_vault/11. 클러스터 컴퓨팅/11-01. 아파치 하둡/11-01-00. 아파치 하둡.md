- # AWS 인스턴스 배포 및 SSH 설정
EC2 접속 후
`ssh-keygen -t rsa`
`cat >> ~/.ssh/authorized_keys < ~/.ssh/id_rsa.pub`
- # Java 설치 및 환경설정
	```
	# EC2 Ubuntu terminal
	
	# 설치 가능한 리스트 업데이트
	$ sudo apt-get -y update
	
	# 업데이트한 패키지들을 최신 버전에 맞게 업그레이드
	$ sudo apt-get -y upgrade
	
	# 의존성까지 체크해서 업그레이드
	$ sudo apt-get -y dist-upgrade
	
	# 필요 라이브러리 설치
	$ sudo apt-get install -y vim wget unzip ssh openssh-* net-tools tree
	
	# Ubuntu 20.4 에는 native libray 인 snappy 가 설치되어 있지 않다.
	# 아래 snappy 설치를 하지 않으면 하둡 설치 후 snappy 사용 시 에러가 발생한다.
	$ sudo apt install libsnappy-dev -y
	```
	- ## openjdk-8 설치
		```
		# EC2 Ubuntu terminal
		
		# Java 8 설치
		$ sudo apt-get install -y openjdk-8-jdk
		
		# Java 버전 확인
		$ java -version
		
		# Java 경로 확인
		$ sudo find / -name java-8-openjdk-amd64 2>/dev/null
		# /usr/lib/jvm/java-8-openjdk-amd64
		```
	- ## Java 환경변수 설정
		```
		# EC2 Ubuntu terminal
		
		# Java 시스템 환경변수 등록 및 활성화
		$ sudo vim /etc/environment
		
		# 아래 내용 추가 후 저장
		PATH 뒤에 ":/usr/lib/jvm/java-8-openjdk-amd64/bin" 추가
		JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"
		
		# 시스템 환경변수 활성화
		$ source /etc/environment
		
		# 사용자 환경변수 등록
		$ sudo echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> ~/.bashrc
		
		# 사용자 환경변수 활성화
		$ source ~/.bashrc
		```
		![](https://i.imgur.com/bFpGDhO.png)
		`cat ~/.bashrc`
		![300](https://i.imgur.com/rdyrGFX.png)
		환경 변수가 잘 등록되었는지 확인
		![200](https://i.imgur.com/BvhxkVw.png)
- # 하둡 에코시스템 베이스 이미지 설치
	- ## Snappy native library 설치
		- 하둡에서 사용하는 snappy native library 설치
		```bash
		sudo apt install libsnappy-dev -y
		```
	- ## Mariadb Client 설치
		- Hive 에서 사용하는 Metastore 로 Mariadb 사용
		```bash
		sudo apt-get install -y mariadb-client
		```
	- ## Python 설치
		- Python3 설치 및 파이썬 라이브러리 설치
		```bash
		sudo apt-get install -y python3-pip
	```
	- ### Anaconda 설치
		- 설치 스크립트 다운로드
		```bash
		mkdir ~/downloads && cd downloads
		```
		```bash
		wget <https://repo.anaconda.com/archive/Anaconda3-2023.03-Linux-x86_64.sh>
		```
		- 아나콘다 설치 스크립트 실행
		```bash
		bash Anaconda3-2023.03-Linux-x86_64.sh
		```
		- 설치과정
		    - `Enter` 키를 누름
		    - MORE 나오면 `스페이스바` 클릭
		    - 라이선스 동의: `yes` 입력
		    - 설치 경로: 기본 경로를 사용하려면 `Enter` 키를 누르세요.
		    - `conda init` 실행: 설치 완료 후 Conda를 초기화하려면 `yes`를 입력하세요.
		- 환경 변수 적용
		```bash
		source ~/.bashrc
		```
	- ## 가상환경 생성
		- pyspark 콘다 가상환경 생성
		```bash
		conda create --name pyspark python=3.8
		```
		- 가상환경 활성화
		```bash
		conda activate pyspark
		```
	- ## PySpark 설치
		- 콘다로 PySpark 설치 (오래 걸림)
		```bash
		conda install -c conda-forge pyspark
		```
	- ## [ 플랫폼 설치 ]
		- ### 플랫폼 다운로드 디렉토리 생성 및 플랫폼 다운로드
		```bash
		cd ~/downloads
		
		wget <https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz>
		```
		- ### spark 다운로드
		```bash
		wget <https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz>
		```
		- ### zookeeper 다운로드
		```bash
		wget <https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz>
		```
		- ### kafka 다운로드
		```bash
		wget <https://downloads.apache.org/kafka/3.6.2/kafka_2.12-3.6.2.tgz>
		```
		- ### hive 다운로드
		```bash
		wget <https://downloads.apache.org/hive/hive-3.1.3/apache-hive-3.1.3-bin.tar.gz>
		```
		- ### zeppelin 다운로드
		```bash
		wget <https://dlcdn.apache.org/zeppelin/zeppelin-0.10.1/zeppelin-0.10.1-bin-all.tgz>
		```
		- ### flume 다운로드
		```bash
		wget <https://dlcdn.apache.org/flume/1.11.0/apache-flume-1.11.0-bin.tar.gz>
		```
		- 압축 해제
		```bash
		sudo tar -xzvf hadoop-3.3.6.tar.gz -C /usr/local
		sudo tar -xzvf spark-3.5.1-bin-hadoop3.tgz -C /usr/local
		sudo tar -xzvf apache-zookeeper-3.8.4-bin.tar.gz -C /usr/local
		sudo tar -xzvf kafka_2.12-3.6.2.tgz -C /usr/local
		sudo tar -xzvf apache-hive-3.1.3-bin.tar.gz -C /usr/local/
		sudo tar -zxvf zeppelin-0.10.1-bin-all.tgz -C /usr/local/
		sudo tar -xzvf apache-flume-1.11.0-bin.tar.gz -C /usr/local
		```
		- 심볼릭 링크 생성
		```bash
		cd /usr/local
		
		sudo ln -s hadoop-3.3.6 hadoop
		sudo ln -s spark-3.5.1-bin-hadoop3 spark
		sudo ln -s apache-zookeeper-3.8.4-bin zookeeper
		sudo ln -s kafka_2.12-3.6.2 kafka
		sudo ln -s apache-hive-3.1.3-bin hive
		sudo ln -s zeppelin-0.10.1-bin-all zeppelin
		sudo ln -s apache-flume-1.11.0-bin flume
		
		```
		- 소유권 변경
		```bash
		sudo chown -R $USER:$USER /usr/local/
		```
	- ## [ 환경변수 설정 ]
		
		- 환경 변수 설정을 한다.
		
		```bash
		sudo vim /etc/environment
		```
		
		- 전체 내용을 아래로 변경
		
		```bash
		PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin:/usr/local/hadoop/bin:/usr/local/hadoop/sbin:/usr/local/spark/bin:/usr/local/spark/sbin:/usr/bin/python3:/usr/local/zookeeper/bin:/usr/local/kafka/bin:/usr/local/hive/bin:/usr/local/zeppelin/bin:/usr/local/flume/bin"
		
		JAVA_HOME="/usr/lib/jvm/java-8-openjdk-amd64"
		HADOOP_HOME="/usr/local/hadoop"
		SPARK_HOME="/usr/local/spark"
		ZOOKEEPER_HOME="/usr/local/zookeeper"
		KAFKA_HOME="/usr/local/kafka"
		HIVE_HOME="/usr/local/hive"
		ZEPPELIN_HOME="/usr/local/zeppelin"
		
		```
		
		- .bashrc 에 환경변수 등록 및 적용
		
		```bash
		source /etc/environment
		
		sudo echo 'export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64' >> ~/.bashrc
		sudo echo 'export HADOOP_HOME=/usr/local/hadoop' >> ~/.bashrc
		sudo echo 'export HADOOP_COMMON_HOME=$HADOOP_HOME' >> ~/.bashrc
		sudo echo 'export HADOOP_HDFS_HOME=$HADOOP_HOME' >> ~/.bashrc
		sudo echo 'export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop' >> ~/.bashrc
		sudo echo 'export HADOOP_YARN_HOME=$HADOOP_HOME' >> ~/.bashrc
		sudo echo 'export HADOOP_MAPRED_HOME=$HADOOP_HOME' >> ~/.bashrc
		sudo echo 'export SPARK_HOME=/usr/local/spark' >> ~/.bashrc
		sudo echo 'export PYTHONPATH=/usr/bin/python3' >> ~/.bashrc
		sudo echo 'export PYSPARK_PYTHON=/usr/bin/python3' >> ~/.bashrc
		sudo echo 'export ZOOKEEPER_HOME=/usr/local/zookeeper' >> ~/.bashrc
		sudo echo 'export KAFKA_HOME=/usr/local/kafka' >> ~/.bashrc
		sudo echo 'export KAFKA_HEAP_OPTS="-Xmx512m -Xms512m"' >> ~/.bashrc
		sudo echo 'export HIVE_HOME=/usr/local/hive' >> ~/.bashrc
		sudo echo 'export ZEPPELIN_HOME=/usr/local/zeppelin' >> ~/.bashrc
		
		source ~/.bashrc
		
		```
	- ## [ Hive MySQL Connector ]
	
	- 하이브에서 사용할 mysql-connector 를 다운로드 받아서 lib 폴더로 넣어줍니다.
	
	```bash
	curl -o $HIVE_HOME/lib/mysql-connector-java-8.0.22.jar <https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.22/mysql-connector-java-8.0.22.jar>
	```
	
	- ## [ 하둡과의 Guava 파일 버전 충돌 문제 해결 ]
	
	- hadoop 과 guava 버전 충돌 나는 플랫폼들의 lib 에 hadoop 의 guava 파일을 복사해줍니다.
	
	```bash
	rm $HIVE_HOME/lib/guava-19.0.jar
	cp $HADOOP_HOME/share/hadoop/hdfs/lib/guava-27.0-jre.jar $HIVE_HOME/lib/
	
	```